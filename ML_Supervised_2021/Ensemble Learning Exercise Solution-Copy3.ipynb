{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementing Random Forest From Scratch (30 points)\n",
    "In this exercise you will need to implement a simple version of Random Forest Regressor from scratch. Your model will handle **continuous input and output**. \n",
    "\n",
    "* Compelete the skeleton class below (you should use scikit-learn's `DecisionTreeRegressor` model that the `TreeEnsemble` will use)\n",
    "  - `X` is a matrix of data values (rows are samples, columns are attributes)\n",
    "  - `y` is a vector of corresponding target values\n",
    "  - `n_trees` is the number of trees to create\n",
    "  - `sample_sz` is the size of the sample set to use of each of the trees in the forest (chose the samples randomly, with or without repetition)\n",
    "  - `n_features` is the size of features to sample. This can be a natrual number > 0, or a ratio of the features as a number in range (0,1]\n",
    "  - `min_leaf` is the minimal number of samples in each leaf node of each tree in the forest\n",
    "  \n",
    "\n",
    "* The `predict` function will use mean of the target values of the trees. The result is a vector of predictions matching the number of rows in `X`.\n",
    "\n",
    "* The `oob_mse` function will compute the mean squared error over all **out of bag (oob)** samples. That is, for each sample calculate the squared error using  predictions from the trees that do not contain x in their respective bootstrap sample, then average this score for all samples. See:  [OOB Errors for Random Forests](https://scikit-learn.org/stable/auto_circless/ensemble/plot_ensemble_oob.html).\n",
    "\n",
    "* To check your random forest implementation, use the boston dataset (`from sklearn.datasets import load_boston`)\n",
    "\n",
    "  - Use the following to estimate what are the best hyper parameters to use for your model\n",
    "```\n",
    "for n in [1,5,10,20,50,100]:\n",
    "  for sz in [50,100,300,500]:\n",
    "    for min_leaf in [1,5]:\n",
    "      forest = TreeEnsemble(X, y, n, sz, min_leaf)\n",
    "      mse = forest.oob_mse()\n",
    "      print(\"n_trees:{0}, sz:{1}, min_leaf:{2} --- oob mse: {3}\".format(n, sz, min_leaf, mse))\n",
    "```\n",
    "  \n",
    "  - Using your chosen hyperparameters as a final model, plot the predictions vs. true values of all the samples in the training set . Use something like:\n",
    "  ```\n",
    "  y_hat = forest.predict(X)  # forest is the chosen model\n",
    "  plt.scatter(y_hat, y)\n",
    "  ```\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.388001Z",
     "start_time": "2022-01-16T08:24:32.375068Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "    def __init__(self, X, y, n_trees, sample_sz, n_features, min_leaf):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def oob_mse(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing AdaBoost From Scratch (30 points)\n",
    "\n",
    "\n",
    "*   Implement the AdaBoost algorithm for classification task. Your `AdaBoost` class should receive a method for creating a weak learner, which has a fit and predict methods (**hint**: you can simulate re-weighting of the samples by an appropriate re-sampling of the train set).\n",
    "*   Use your model to find a strong classifier on the sample set given below, using $n$ weak learners:\n",
    "    - For the base weak learners, use a ***linear*** SVM classifier (use `LinearSVC` with the default parameters). \n",
    "    - Split the sample set into train and test sets.\n",
    "    - Plot the final decision plane of your classifier for $n\\in \\{1, 2, 3, 5, 10, 50\\}$, and visualize the final iteration weights of the samples in those plots.\n",
    "    - How does the overall train set accuracy changes with $n$?\n",
    "    - Does you model starts to overfit at some point?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.402947Z",
     "start_time": "2022-01-16T08:24:32.389982Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.45, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.481072Z",
     "start_time": "2022-01-16T08:24:32.404943Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-289b4567d27f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "m = len(X_train)\n",
    "\n",
    "fix, axes = plt.subplots(ncols=2, figsize=(10,4), sharey=True)\n",
    "for subplot, learning_rate in ((0, 1), (1, 0.5)):\n",
    "    sample_weights = np.ones(m) / m\n",
    "    plt.sca(axes[subplot])\n",
    "    for i in range(5):\n",
    "        svm_clf = SVC(kernel=\"rbf\", C=0.2, gamma=0.6, random_state=42)\n",
    "        svm_clf.fit(X_train, y_train, sample_weight=sample_weights * m)\n",
    "        y_pred = svm_clf.predict(X_train)\n",
    "\n",
    "        r = sample_weights[y_pred != y_train].sum() / sample_weights.sum() # equation 7-1\n",
    "        alpha = learning_rate * np.log((1 - r) / r) # equation 7-2\n",
    "        sample_weights[y_pred != y_train] *= np.exp(alpha) # equation 7-3\n",
    "        sample_weights /= sample_weights.sum() # normalization step\n",
    "\n",
    "        plot_decision_boundary(svm_clf, X, y, alpha=0.2)\n",
    "        plt.title(\"learning_rate = {}\".format(learning_rate), fontsize=16)\n",
    "    if subplot == 0:\n",
    "        plt.text(-0.75, -0.95, \"1\", fontsize=14)\n",
    "        plt.text(-1.05, -0.95, \"2\", fontsize=14)\n",
    "        plt.text(1.0, -0.95, \"3\", fontsize=14)\n",
    "        plt.text(-1.45, -0.5, \"4\", fontsize=14)\n",
    "        plt.text(1.36,  -0.95, \"5\", fontsize=14)\n",
    "    else:\n",
    "        plt.ylabel(\"\")\n",
    "\n",
    "save_fig(\"boosting_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:54.185108Z",
     "start_time": "2022-01-16T08:24:51.293997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=1500, noise=0.2, random_state=101, factor=0.5)\n",
    "\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:56.755776Z",
     "start_time": "2022-01-16T08:24:56.215514Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from math import log,exp\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:58.853525Z",
     "start_time": "2022-01-16T08:24:58.835786Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "weight_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:25:07.275320Z",
     "start_time": "2022-01-16T08:25:07.270365Z"
    }
   },
   "outputs": [],
   "source": [
    "circles = pd.DataFrame({'Column1': X[:, 0], 'Column2': X[:, 1]})\n",
    "circles['Label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:25:07.686868Z",
     "start_time": "2022-01-16T08:25:07.678890Z"
    }
   },
   "outputs": [],
   "source": [
    "circles['prob1'] = 1/(circles.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:25:08.112396Z",
     "start_time": "2022-01-16T08:25:08.092450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Label</th>\n",
       "      <th>prob1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.495799</td>\n",
       "      <td>0.323412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.419618</td>\n",
       "      <td>-0.318647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.068761</td>\n",
       "      <td>-0.124953</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.517004</td>\n",
       "      <td>0.383915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.076649</td>\n",
       "      <td>-0.376912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.447559</td>\n",
       "      <td>-0.222795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0.854887</td>\n",
       "      <td>0.887338</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.487560</td>\n",
       "      <td>-0.980803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0.064621</td>\n",
       "      <td>-0.889950</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.547605</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column1   Column2  Label     prob1\n",
       "0    -0.495799  0.323412      1  0.000667\n",
       "1    -0.419618 -0.318647      1  0.000667\n",
       "2    -0.068761 -0.124953      1  0.000667\n",
       "3     0.517004  0.383915      1  0.000667\n",
       "4    -0.076649 -0.376912      1  0.000667\n",
       "...        ...       ...    ...       ...\n",
       "1495  0.447559 -0.222795      1  0.000667\n",
       "1496  0.854887  0.887338      0  0.000667\n",
       "1497  0.487560 -0.980803      0  0.000667\n",
       "1498  0.064621 -0.889950      1  0.000667\n",
       "1499  0.664478  0.547605      1  0.000667\n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:25:21.391711Z",
     "start_time": "2022-01-16T08:25:21.378750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Label</th>\n",
       "      <th>prob1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.188413</td>\n",
       "      <td>-0.610976</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.110184</td>\n",
       "      <td>-0.463169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-1.030785</td>\n",
       "      <td>-0.329508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>-0.449383</td>\n",
       "      <td>0.286480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.141090</td>\n",
       "      <td>-0.988688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column1   Column2  Label     prob1\n",
       "43    0.188413 -0.610976      1  0.000667\n",
       "996  -0.110184 -0.463169      1  0.000667\n",
       "83   -1.030785 -0.329508      0  0.000667\n",
       "1148 -0.449383  0.286480      1  0.000667\n",
       "916   0.141090 -0.988688      0  0.000667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:25:11.092152Z",
     "start_time": "2022-01-16T08:25:10.954075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjlev\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Label</th>\n",
       "      <th>prob1</th>\n",
       "      <th>pred1</th>\n",
       "      <th>misclassified</th>\n",
       "      <th>prob2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.495799</td>\n",
       "      <td>0.323412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.419618</td>\n",
       "      <td>-0.318647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.068761</td>\n",
       "      <td>-0.124953</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.517004</td>\n",
       "      <td>0.383915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.076649</td>\n",
       "      <td>-0.376912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.161664</td>\n",
       "      <td>-0.439531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.252313</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.550185</td>\n",
       "      <td>0.263274</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.329312</td>\n",
       "      <td>-0.043181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.571568</td>\n",
       "      <td>1.022087</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column1   Column2  Label     prob1  pred1  misclassified   prob2\n",
       "0 -0.495799  0.323412      1  0.000667      1            0.0  0.0003\n",
       "1 -0.419618 -0.318647      1  0.000667      1            0.0  0.0003\n",
       "2 -0.068761 -0.124953      1  0.000667      1            0.0  0.0003\n",
       "3  0.517004  0.383915      1  0.000667      1            0.0  0.0003\n",
       "4 -0.076649 -0.376912      1  0.000667      1            0.0  0.0003\n",
       "5 -0.161664 -0.439531      1  0.000667      1            0.0  0.0003\n",
       "6 -0.252313  0.526283      1  0.000667      1            0.0  0.0003\n",
       "7 -0.550185  0.263274      1  0.000667      1            0.0  0.0003\n",
       "8  0.329312 -0.043181      1  0.000667      1            0.0  0.0003\n",
       "9 -0.571568  1.022087      0  0.000667      0            0.0  0.0009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple random sample with replacement\n",
    "random.seed(10)\n",
    "circles1 = circles.sample(len(circles), replace = True, weights = circles['prob1'])\n",
    "#X_train and Y_train split\n",
    "X_train = circles1.iloc[0:len(circles),0:2]\n",
    "y_train = circles1.iloc[0:len(circles),2]\n",
    "#fitting the DT model with depth one\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "clf = classifier.fit(X, y)\n",
    "#prediction\n",
    "y_pred = classifier.predict(circles.iloc[0:len(circles),0:2])\n",
    "circles['pred1'] = y_pred\n",
    "#misclassified = 0 if the label and prediction are same\n",
    "circles.loc[circles['Label'] == circles.pred1, 'misclassified'] = 0\n",
    "circles.loc[circles['Label'] != circles.pred1, 'misclassified'] = 1\n",
    "error = sum(circles['misclassified'] * circles['prob1'])# /len(circles)\n",
    "weight = learning_rate*log((1-error)/error)\n",
    "weight_list.append(weight)\n",
    "#update weight\n",
    "new_weight = circles['prob1']*np.exp(-1*weight*circles['Label']*circles['pred1'])\n",
    "#normalized weight\n",
    "# z = sum(new_weight)\n",
    "normalized_weight = new_weight/sum(new_weight)\n",
    "circles['prob2'] = round(normalized_weight,4)\n",
    "circles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:26:22.405513Z",
     "start_time": "2022-01-16T08:26:22.321708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9172629161118349\n",
      "0.7988618488389417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjlev\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jjlev\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "l = str(2)\n",
    "M = 2\n",
    "for m in range(M):\n",
    "    num_pred = \"pred\" + l\n",
    "    num_misclass = \"misclassified\" + l\n",
    "    num_prob = \"prob\" + l\n",
    "    random.seed(20)\n",
    "    circles_temp = circles.sample(len(circles), replace = True, weights = circles['prob2'])\n",
    "    circles_temp = circles_temp.iloc[:,0:3]\n",
    "    X_train = circles_temp.iloc[0:len(circles),0:2]\n",
    "    y_train = circles_temp.iloc[0:len(circles),2]\n",
    "\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    clf = classifier.fit(X, y)\n",
    "\n",
    "    y_pred = classifier.predict(circles.iloc[0:len(circles),0:2])\n",
    "    #adding a column pred2 after the second round of boosting\n",
    "    circles[num_pred] = y_pred\n",
    "\n",
    "    #adding a field misclassified\n",
    "    circles.loc[circles['Label'] == circles[num_pred], num_misclass] = 0\n",
    "    circles.loc[circles['Label'] != circles[num_pred], num_misclass] = 1\n",
    "\n",
    "    # calculation of error\n",
    "    error = sum(circles[num_misclass] * circles[num_prob])# /len(circles)\n",
    "    # print(error)\n",
    "    \n",
    "    #calculation of weights\n",
    "    weight = learning_rate*log((1-error)/error)\n",
    "    weight_list.append(weight)\n",
    "    print(weight)\n",
    "#     print(num_pred)\n",
    "#     print(circles[num_pred])\n",
    "#     print(weight2)\n",
    "\n",
    "    #update weight\n",
    "    new_weight = circles[num_prob]*np.exp(-1*weight*circles['Label']*circles[num_pred])\n",
    "    # print(new_weight)\n",
    "    # z = sum(new_weight)\n",
    "    normalized_weight = new_weight/sum(new_weight)\n",
    "    # print(normalized_weight)\n",
    "    l = int(l)+1\n",
    "    l = str(l)\n",
    "    num_prob_p = \"prob\" + l\n",
    "    circles[num_prob_p] = round(normalized_weight,4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:26:57.162898Z",
     "start_time": "2022-01-16T08:26:57.133148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>-0.531297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>1.052127</td>\n",
       "      <td>0.563368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-1.037654</td>\n",
       "      <td>0.447629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>-0.038964</td>\n",
       "      <td>-1.005537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.329079</td>\n",
       "      <td>0.140998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>-0.874770</td>\n",
       "      <td>0.549524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.379233</td>\n",
       "      <td>-1.243899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.032952</td>\n",
       "      <td>0.604765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.146792</td>\n",
       "      <td>-1.001921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-0.859073</td>\n",
       "      <td>-0.965434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column1   Column2  Label\n",
       "1306  0.046081 -0.531297      1\n",
       "981   1.052127  0.563368      0\n",
       "311  -1.037654  0.447629      0\n",
       "509  -0.038964 -1.005537      0\n",
       "78    0.329079  0.140998      1\n",
       "...        ...       ...    ...\n",
       "911  -0.874770  0.549524      0\n",
       "25    0.379233 -1.243899      0\n",
       "766   1.032952  0.604765      0\n",
       "512   0.146792 -1.001921      0\n",
       "174  -0.859073 -0.965434      0\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.492043Z",
     "start_time": "2022-01-16T08:24:32.402Z"
    }
   },
   "outputs": [],
   "source": [
    "# final \n",
    "m = m + 1 \n",
    "num_pred = \"pred\" + str(m)\n",
    "num_misclass = \"misclassified\" + str(m)\n",
    "num_prob = \"prob\" + str(m)\n",
    "random.seed(20)\n",
    "circles_final = circles.sample(len(circles), replace = True, weights = circles[num_prob])\n",
    "circles_final = circles_final.iloc[:,0:3]\n",
    "X_train = circles_final.iloc[0:len(circles),0:2]\n",
    "y_train = circles_final.iloc[0:len(circles),2]\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "clf = classifier.fit(X, y)\n",
    "\n",
    "#adding a column pred4 after the fourth round of boosting\n",
    "y_pred = classifier.predict(circles.iloc[0:len(circles),0:2])\n",
    "circles[num_pred] = y_pred\n",
    "\n",
    "# #plotting tree for round 4 boosting\n",
    "# tree.plot_tree(clf)\n",
    "\n",
    "#adding a field misclassified4\n",
    "circles.loc[circles['Label'] == circles[num_pred], num_misclass] = 0\n",
    "circles.loc[circles['Label'] != circles[num_pred], num_misclass] = 1\n",
    "\n",
    "#error calculation\n",
    "error = sum(circles[num_misclass] * circles[num_prob])# /len(circles)\n",
    "error\n",
    "\n",
    "# calculation of performance (weight)\n",
    "weight = learning_rate*log((1-error)/error)\n",
    "weight_list.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.493040Z",
     "start_time": "2022-01-16T08:24:32.405Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_final = weight_list[0] * circles['pred1'] + weight_list[1] * circles['pred2'] + weight_list[2] * circles['pred3'] + weight_list[3] * circles['pred4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.494038Z",
     "start_time": "2022-01-16T08:24:32.407Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sign(list(y_pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.495036Z",
     "start_time": "2022-01-16T08:24:32.409Z"
    }
   },
   "outputs": [],
   "source": [
    "circles['final_pred'] = np.sign(list(y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.496033Z",
     "start_time": "2022-01-16T08:24:32.410Z"
    }
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "c=confusion_matrix(circles['Label'], circles['final_pred'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.497033Z",
     "start_time": "2022-01-16T08:24:32.411Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X, y\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 0, stop = X_set[:, 0].max() + 0, step = 0.25),\n",
    "                     np.arange(start = X_set[:, 1].min() - 0, stop = X_set[:, 1].max() + 0, step = 0.25))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Kernel SVM (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.498028Z",
     "start_time": "2022-01-16T08:24:32.414Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X, y\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 0, stop = X_set[:, 0].max() + 0, step = 0.25),\n",
    "                     np.arange(start = X_set[:, 1].min() - 0, stop = X_set[:, 1].max() + 0, step = 0.25))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Kernel SVM (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Boosting Trees from Scratch (40 points)\n",
    "* Use the scikit-learn's DecisionTreeRegressor (again :) with `max_depth = 1` (stumps)  to write a L2Boost model which minimize the L2 square loss iteration by iteration.\n",
    "Reminder: in each step, build a decision tree to minimize the error between the true label and the accumulated (sum) of the previous step predictions.\n",
    "![alt text](https://explained.ai/gradient-boosting/images/latex-321A7951E78381FB73D2A6874916134D.svg)\n",
    "* Use the Boston dataset to plot the MSE as a function of the number of trees for a logspace of `n_trees` up to 1,000. What is the optimal value of `n_trees`? of learning rate?\n",
    "* Compare the performance with a deep DecisionTreeRegressor (find the optimal `max_depth`).  Who wins?\n",
    "* Add an early-stopping mechanisim to the GBTL2 model to use a validation set to detect over-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.500036Z",
     "start_time": "2022-01-16T08:24:32.417Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500)\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\", fontsize=16)\n",
    "    plt.axis(axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.501021Z",
     "start_time": "2022-01-16T08:24:32.419Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "X,y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.502017Z",
     "start_time": "2022-01-16T08:24:32.421Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "X,y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.503015Z",
     "start_time": "2022-01-16T08:24:32.422Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "          for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.504012Z",
     "start_time": "2022-01-16T08:24:32.424Z"
    }
   },
   "outputs": [],
   "source": [
    "min_error = np.min(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.505024Z",
     "start_time": "2022-01-16T08:24:32.426Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(errors, \"b.-\")\n",
    "plt.plot([bst_n_estimators, bst_n_estimators], [0, min_error], \"k--\")\n",
    "plt.plot([0, 120], [min_error, min_error], \"k--\")\n",
    "plt.plot(bst_n_estimators, min_error, \"ko\")\n",
    "plt.text(bst_n_estimators, min_error*1.2, \"Minimum\", ha=\"center\", fontsize=14)\n",
    "plt.axis([0, 120, 0, 0.01])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Error\", fontsize=16)\n",
    "plt.title(\"Validation error\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
    "plt.title(\"Best model (%d trees)\" % bst_n_estimators, fontsize=14)\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "\n",
    "# save_fig(\"early_stopping_gbrt_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.505024Z",
     "start_time": "2022-01-16T08:24:32.427Z"
    }
   },
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T08:24:32.506006Z",
     "start_time": "2022-01-16T08:24:32.429Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,11))\n",
    "\n",
    "plt.subplot(321)\n",
    "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h_1(x_1)$\", style=\"g-\", data_label=\"Training set\")\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "plt.title(\"Residuals and tree predictions\", fontsize=16)\n",
    "\n",
    "save_fig(\"gradient_boosting_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
